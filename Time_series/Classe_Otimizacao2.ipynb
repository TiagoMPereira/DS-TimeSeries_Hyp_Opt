{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQzGr6N2sHmd"
   },
   "source": [
    "### Otimização em classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSV0oUBIsHnd"
   },
   "source": [
    "#### Métodos de otimização\n",
    "* Grid Search\n",
    "* Random Search\n",
    "* Bayesian Search\n",
    "* Genetic Algorithms\n",
    "* Population Based Training\n",
    "\n",
    "#### Algoritmos de ML/DL\n",
    "* Support Vector Machines\n",
    "* KNN\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* AdaBoost\n",
    "* Gradient Boosting\n",
    "* XGBoost\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxIB4vo4wJYA"
   },
   "source": [
    "Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRWRQxgJwJHQ",
    "outputId": "257f48e6-025f-4dfc-b7eb-103b2bdc317a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
      "\r",
      "\u001b[K     |███▎                            | 10kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 20kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 30kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 40kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 51kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 61kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 71kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 81kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 92kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 102kB 3.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"
     ]
    }
   ],
   "source": [
    "#Bayes opt\n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JToGe1CFwPYA"
   },
   "outputs": [],
   "source": [
    "#pbt\n",
    "!pip install parameter-sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_94ZVLRZDafi"
   },
   "outputs": [],
   "source": [
    "#Recolhendo dados da prata e preparando dataset\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import datetime as dt\n",
    "\n",
    "end = dt.datetime(2020, 6, 1)\n",
    "start = dt.datetime(2018, 1, 1)\n",
    "\n",
    "df = web.DataReader(\"FB\", 'yahoo', start, end)\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=['Open','Date','High','Low','Volume','Adj Close'])\n",
    "df = df.rename(columns={'Close': 'Close 0'})\n",
    "\n",
    "def window (df, w):\n",
    "    for i in range(1,w):\n",
    "        df['Close '+str(i)] = df['Close '+str(i-1)].shift(1)\n",
    "    return df\n",
    "        \n",
    "df = window(df,5)\n",
    "df = df.rename(columns={'Close 0': 'Target'})\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Separando dados de treino e teste\n",
    "X = df.loc[:, ['Close 1','Close 2','Close 3','Close 4']]\n",
    "y = df.loc[:, 'Target'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3t5tcmmsHng"
   },
   "source": [
    "### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_zeHKsoLsHnj"
   },
   "outputs": [],
   "source": [
    "#bibliotecas padrão\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "#Algoritmos ML\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#Redes neurais\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "#Métodos de otimização\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV #Grid e random search\n",
    "from skopt import BayesSearchCV #Bayes\n",
    "import sherpa #PBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOsK_88MsHnq"
   },
   "source": [
    "### Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Djys56kgsHns"
   },
   "outputs": [],
   "source": [
    "class Otimizacao(ABC):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.time = 0\n",
    "        self.time_tuned = 0\n",
    "        self.time_default = 0\n",
    "        self.score = 0\n",
    "        self.score_default = 0\n",
    "        self.score_tuned = 0\n",
    "        self.best_hp = {}\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        print(\"Class Created\")\n",
    "        \n",
    "    #Hiperparâmetros\n",
    "    def getHP(self):\n",
    "        pass\n",
    "    \n",
    "    #Treinando modelo padrão\n",
    "    def fit_default(self):\n",
    "        \n",
    "        time_begin = time.time()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_default = (time.time() - time_begin) + 0.00001\n",
    "        \n",
    "        \n",
    "        #Pontuação\n",
    "        self.score_default = self.model.score(self.X_test, self.y_test)\n",
    "        \n",
    "        #Busca pelo espaço hiperparamétrico\n",
    "    def fit_tuned(self):\n",
    "        \n",
    "        time_begin = time.time()\n",
    "        self.model_tuned.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_tuned = time.time() - time_begin\n",
    "        \n",
    "        #Pontuação \n",
    "        self.score_tuned = self.model_tuned.score(self.X_test, self.y_test)\n",
    "        \n",
    "        #Melhores hiperparâmetros\n",
    "        self.best_hp = self.model_tuned.best_params_\n",
    "        \n",
    "    #Relatório\n",
    "    def report(self):\n",
    "        print(\"Modelo: \", self.name)\n",
    "        print(\"--Pontuações--\")\n",
    "        print(\"Padrão: \", self.score_default)\n",
    "        print(\"Ajustado: \", self.score_tuned)\n",
    "        print(\"Relativo: \", self.score)\n",
    "        print(\"--Tempos--\")\n",
    "        print(\"Padrão: \", self.time_default)\n",
    "        print(\"Ajustado: \", self.time_tuned)\n",
    "        print(\"Relativo: \", self.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yhmZ95tsHnt"
   },
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XCzYDCTRsHnw"
   },
   "outputs": [],
   "source": [
    "class GridSearch(Otimizacao):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Otimizacao.__init__(self)\n",
    "\n",
    "    \n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #Dados de treino\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        #Espaço hiperparamétrico\n",
    "        self.getHP()\n",
    "        \n",
    "        #Modelo de treino\n",
    "        self.model_tuned = self.model_tuned = GridSearchCV(self.model, self.hyp, verbose=3, cv=3)\n",
    "        \n",
    "        #Funções de treinamento\n",
    "        self.fit_default()\n",
    "        self.fit_tuned()\n",
    "        \n",
    "        #Pontuações relativas\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        \n",
    "        #Relatório\n",
    "        self.report()\n",
    "        \n",
    "        \n",
    "    #Relatório\n",
    "    def report(self):\n",
    "        print(\"Grid Search Report\")\n",
    "        Otimizacao.report(self)\n",
    "        print(\"--Melhor configuração--\")\n",
    "        print(self.best_hp)\n",
    "        \n",
    "# Support vector machine\n",
    "class GridSearchSVM(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"SVM\"\n",
    "        self.model = SVR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        kernel = ['rbf','linear']\n",
    "        C = (np.arange(1,10)/10).tolist() #0.1 - 0.9 - 0.1\n",
    "        epsilon = [] #0.001 - 0.9\n",
    "        for j in range(1,4): \n",
    "            for i in range(1,10):\n",
    "                epsilon.append(i/(10**j))\n",
    "\n",
    "        self.hyp = {'kernel': kernel, 'C':C, 'epsilon':epsilon}\n",
    "        \n",
    "#KNN\n",
    "class GridSearchKNN(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"KNN\"\n",
    "        self.model = KNR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_n = (np.arange(5,14,2)).tolist() #de 5 até 13\n",
    "        weights = ['uniform','distance']\n",
    "        p = [1,2]\n",
    "\n",
    "        self.hyp = {'n_neighbors':n_n, 'weights':weights, 'p':p }\n",
    "        \n",
    "#Decision Tree\n",
    "class GridSearchDT(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"Decision Tree\"\n",
    "        self.model = DecisionTreeRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        min_s_split = (np.arange(2,21,2)).tolist() #2 - 20 - 2\n",
    "        max_feat = (np.arange(50,100,5)/100).tolist() #0.5 - 0.95 - 0.05\n",
    "        max_depth = (np.arange(10,100,10)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21,5)/100).tolist() #0.05 - 0.2\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        spliter = ['best']\n",
    "\n",
    "        self.hyp = {'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_depth, \n",
    "                    'criterion':criterion, 'splitter':spliter, 'min_samples_leaf': min_s_leaf}\n",
    "        \n",
    "#Random Forest\n",
    "class GridSearchRF(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"Random Forest\"\n",
    "        self.model = RandomForestRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751, 10)).tolist() #50 - 750 - 10\n",
    "        min_s_split = (np.arange(2,21,2)).tolist() #2 - 20 - 2\n",
    "        max_feat = (np.arange(20,100,5)/100).tolist() #0.2 - 0.95 - 0.0\n",
    "        criterion = ['mse','mae']\n",
    "        max_dpt = (np.arange(10,100,10)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21,5)/100).tolist() #0.05 - 0.2\n",
    "        max_samp = (np.arange(50,100,5)/100).tolist() #0.5 - 0.99\n",
    "        oob = [True,False]\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_dpt,\n",
    "                  'min_samples_leaf': min_s_leaf, 'max_samples': max_samp, 'criterion':criterion, 'oob_score':oob}\n",
    "        \n",
    "#Ada Boost\n",
    "class GridSearchADB(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"AdaBoost\"\n",
    "        self.model = AdaBoostRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751,20)).tolist() #50 - 750\n",
    "        loss = ['linear','exponential','square']\n",
    "        lr = [] #0.001 - 0.9\n",
    "        for j in range(1,3): \n",
    "            for i in range(1,10):\n",
    "                lr.append(i/(10**j))\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate': lr, 'loss':loss}\n",
    "        \n",
    "#Gradient Boosting\n",
    "class GridSearchGDB(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"Gradient Boosting\"\n",
    "        self.model = GradientBoostingRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751,10)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21,2)).tolist() #2 - 20 - 2\n",
    "        sub = (np.arange(5,10)/10).tolist() #0.5 - 0.9\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        min_s_leaf = (np.arange(5,21,5)/100).tolist() #0.05 - 0.2\n",
    "        max_feat = (np.arange(20,100,5)/100).tolist() #0.2 - 0.95 - 0.05\n",
    "        max_dpt = (np.arange(10,100,10)).tolist() #10 - 100\n",
    "        alpha = (np.arange(50,100,10)/100).tolist() #0.5 - 0.99\n",
    "        lr = [0.005, 0.006, 0.007, 0.008, 0.009] #0.001 - 0.9\n",
    "\n",
    "        self.hyp = [\n",
    "                {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, 'criterion': criterion, 'min_samples_leaf': min_s_leaf,\n",
    "                  'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, 'loss': ['ls', 'lad'] },\n",
    "                {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, 'criterion': criterion, 'min_samples_leaf': min_s_leaf,\n",
    "                  'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, 'loss': ['huber', 'quantile'], 'alpha': alpha}\n",
    "          ]\n",
    "        \n",
    "#XGBoost\n",
    "class GridSearchXGB(GridSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GridSearch.__init__(self)\n",
    "        self.name = \"XGBoost\"\n",
    "        self.model = XGBRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751,10)).tolist() #50 - 750\n",
    "        bst = ['gbtree','gblinear','dart']\n",
    "        lr = [] #0.001 - 0.9\n",
    "        for j in range(1,4): \n",
    "            for i in range(1,10):\n",
    "                lr.append(i/(10**j))\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate':lr,'booster':bst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ3yINJUsHn9"
   },
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nh2hzu1nsHoP"
   },
   "outputs": [],
   "source": [
    "class RandomSearch(Otimizacao):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Otimizacao.__init__(self)\n",
    "    \n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #Dados de treino\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        #Espaço hiperparamétrico\n",
    "        self.getHP()\n",
    "        \n",
    "        #Modelo de treino\n",
    "        self.model_tuned = self.model_tuned = RandomizedSearchCV(self.model, self.hyp, verbose=3, cv=3, n_iter = 30)\n",
    "        \n",
    "        #Funções de treinamento\n",
    "        self.fit_default()\n",
    "        self.fit_tuned()\n",
    "        \n",
    "        #Pontuações relativas\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        \n",
    "        #Relatório\n",
    "        self.report()\n",
    "        \n",
    "        \n",
    "    #Relatório\n",
    "    def report(self):\n",
    "        print(\"Random Search Report\")\n",
    "        Otimizacao.report(self)\n",
    "        print(\"--Melhor configuração--\")\n",
    "        print(self.best_hp)\n",
    "        \n",
    "# Support vector machine\n",
    "class RandomSearchSVM(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"SVM\"\n",
    "        self.model = SVR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        kernel = ['rbf','linear']\n",
    "        C = (np.arange(10,100)/100).tolist() #0.1 - 0.99\n",
    "        epsilon = (np.arange(1,1000)/1000).tolist() #0.001 - 0.999\n",
    "\n",
    "        self.hyp = {'kernel': kernel, 'C':C, 'epsilon':epsilon}\n",
    "        \n",
    "#KNN\n",
    "class RandomSearchKNN(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"KNN\"\n",
    "        self.model = KNR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_n = (np.arange(5,14,2)).tolist() #de 5 até 13\n",
    "        weights = ['uniform','distance']\n",
    "        p = [1,2]\n",
    "\n",
    "        self.hyp = {'n_neighbors':n_n, 'weights':weights, 'p':p }\n",
    "        \n",
    "#Decision Tree\n",
    "class RandomSearchDT(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"Decision Tree\"\n",
    "        self.model = DecisionTreeRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        max_feat = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "        max_depth = (np.arange(10,100)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        spliter = ['best']\n",
    "\n",
    "        self.hyp = {'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_depth, \n",
    "                    'criterion':criterion, 'splitter':spliter, 'min_samples_leaf': min_s_leaf}\n",
    "        \n",
    "#Random Forest\n",
    "class RandomSearchRF(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"Random Forest\"\n",
    "        self.model = RandomForestRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        max_feat = (np.arange(2,10)/10).tolist() #0.2 - 0.9\n",
    "        criterion = ['mse','mae']\n",
    "        max_dpt = (np.arange(10,50,5)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        max_samp = (np.arange(50,100,5)/100).tolist() #0.5 - 0.99\n",
    "        oob = [True,False]\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_dpt,\n",
    "                  'min_samples_leaf': min_s_leaf, 'max_samples': max_samp, 'criterion':criterion, 'oob_score':oob}\n",
    "        \n",
    "#Ada Boost\n",
    "class RandomSearchADB(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"AdaBoost\"\n",
    "        self.model = AdaBoostRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        lr = (np.arange(1,1000)/1000).tolist() #0.001 - 0.999\n",
    "        loss = ['linear','exponential','square']\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate': lr, 'loss':loss}\n",
    "        \n",
    "#Gradient Boosting\n",
    "class RandomSearchGDB(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"Gradient Boosting\"\n",
    "        self.model = GradientBoostingRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        sub = (np.arange(5,10)/10).tolist() #0.5 - 0.9\n",
    "        lr = (np.arange(5,1000)/1000).tolist() # 0.005 - 0.999\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        max_feat = (np.arange(2,10)/10).tolist() #0.2 - 0.9\n",
    "        max_dpt = (np.arange(10,100)).tolist() #10 - 100\n",
    "        alpha = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "\n",
    "        self.hyp = [\n",
    "                {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, 'criterion': criterion, 'min_samples_leaf': min_s_leaf,\n",
    "                  'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, 'loss': ['ls', 'lad'] },\n",
    "                {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, 'criterion': criterion, 'min_samples_leaf': min_s_leaf,\n",
    "                  'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, 'loss': ['huber', 'quantile'], 'alpha': alpha}\n",
    "          ]\n",
    "        \n",
    "#XGBoost\n",
    "class RandomSearchXGB(RandomSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        RandomSearch.__init__(self)\n",
    "        self.name = \"XGBoost\"\n",
    "        self.model = XGBRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        lr = (np.arange(1,100)/100).tolist() # 0.01 - 0.99\n",
    "        bst = ['gbtree','gblinear','dart']\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate':lr,'booster':bst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7ANwBElsHoZ"
   },
   "source": [
    "### Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YXx46vmUsHoa"
   },
   "outputs": [],
   "source": [
    "class BayesianSearch(Otimizacao):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Otimizacao.__init__(self)\n",
    "    \n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #Dados de treino\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        #Espaço hiperparamétrico\n",
    "        self.getHP()\n",
    "        \n",
    "        #Modelo de treino\n",
    "        self.model_tuned = self.model_tuned = BayesSearchCV(self.model, self.hyp, n_iter= 30, verbose=1)\n",
    "        \n",
    "        #Funções de treinamento\n",
    "        self.fit_default()\n",
    "        self.fit_tuned()\n",
    "        \n",
    "        #Pontuações relativas\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        \n",
    "        #Relatório\n",
    "        self.report()\n",
    "        \n",
    "        \n",
    "    #Relatório\n",
    "    def report(self):\n",
    "        print(\"Bayesian Search Report\")\n",
    "        Otimizacao.report(self)\n",
    "        print(\"--Melhor configuração--\")\n",
    "        print(self.best_hp)\n",
    "        \n",
    "# Support vector machine\n",
    "class BayesianSearchSVM(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"SVM\"\n",
    "        self.model = SVR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        kernel = ['rbf','linear']\n",
    "        C = (np.arange(10,100)/100).tolist() #0.1 - 0.99\n",
    "        epsilon = (np.arange(1,1000)/1000).tolist() #0.001 - 0.999\n",
    "\n",
    "        self.hyp = {'kernel': kernel, 'C':C, 'epsilon':epsilon}\n",
    "        \n",
    "#KNN\n",
    "class BayesianSearchKNN(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"KNN\"\n",
    "        self.model = KNR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_n = (np.arange(5,14,2)).tolist() #de 5 até 13\n",
    "        weights = ['uniform','distance']\n",
    "        p = [1,2]\n",
    "\n",
    "        self.hyp = {'n_neighbors':n_n, 'weights':weights, 'p':p }\n",
    "        \n",
    "#Decision Tree\n",
    "class BayesianSearchDT(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"Decision Tree\"\n",
    "        self.model = DecisionTreeRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        max_feat = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "        max_depth = (np.arange(10,100)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        spliter = ['best']\n",
    "\n",
    "        self.hyp = {'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_depth, \n",
    "                    'criterion':criterion, 'splitter':spliter, 'min_samples_leaf': min_s_leaf}\n",
    "        \n",
    "#Random Forest\n",
    "class BayesianSearchRF(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"Random Forest\"\n",
    "        self.model = RandomForestRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        max_feat = (np.arange(2,10)/10).tolist() #0.2 - 0.9\n",
    "        criterion = ['mse','mae']\n",
    "        max_dpt = (np.arange(10,100)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        max_samp = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "        oob = [True,False]\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_dpt,\n",
    "                  'min_samples_leaf': min_s_leaf, 'max_samples': max_samp, 'criterion':criterion, 'oob_score':oob}\n",
    "        \n",
    "#Ada Boost\n",
    "class BayesianSearchADB(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"AdaBoost\"\n",
    "        self.model = AdaBoostRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        lr = (np.arange(1,1000)/1000).tolist() #0.001 - 0.999\n",
    "        loss = ['linear','exponential','square']\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate': lr, 'loss':loss}\n",
    "        \n",
    "#Gradient Boosting\n",
    "class BayesianSearchGDB(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"Gradient Boosting\"\n",
    "        self.model = GradientBoostingRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        sub = (np.arange(5,10)/10).tolist() #0.5 - 0.9\n",
    "        lr = (np.arange(5,1000)/1000).tolist() # 0.005 - 0.999\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        max_feat = (np.arange(2,10)/10).tolist() #0.2 - 0.9\n",
    "        max_dpt = (np.arange(10,100)).tolist() #10 - 100\n",
    "        alpha = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "\n",
    "        self.hyp = [\n",
    "                {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, 'criterion': criterion, 'min_samples_leaf': min_s_leaf,\n",
    "                  'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, 'loss': ['ls', 'lad'] },\n",
    "                {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, 'criterion': criterion, 'min_samples_leaf': min_s_leaf,\n",
    "                  'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, 'loss': ['huber', 'quantile'], 'alpha': alpha}\n",
    "          ]\n",
    "        \n",
    "#XGBoost\n",
    "class BayesianSearchXGB(BayesianSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        BayesianSearch.__init__(self)\n",
    "        self.name = \"XGBoost\"\n",
    "        self.model = XGBRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        lr = (np.arange(1,100)/100).tolist() # 0.01 - 0.99\n",
    "        bst = ['gbtree','gblinear','dart']\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate':lr,'booster':bst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COCizHzCsHox"
   },
   "source": [
    "### Genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ns6e4hdNsHoy"
   },
   "outputs": [],
   "source": [
    "class GeneticSearch(Otimizacao):\n",
    "    \n",
    "    def __init__(self, n_geracoes=10, populacao=10, space = {}):\n",
    "        self.geracoes = n_geracoes\n",
    "        self.pop = populacao\n",
    "        self.cromo = []\n",
    "        self.pontos = []\n",
    "        self.final_pont_max = []\n",
    "        self.pontos_max = 0\n",
    "        self.max_pontos = 100\n",
    "        self.id_max = 0\n",
    "        self.vencedor = []\n",
    "        self.dict_ = list(space)\n",
    "        self.space = list(space.values())\n",
    "        self.types = []\n",
    "        self.top_pontos = []\n",
    "        self.top_cromos = []\n",
    "        self.max_val = dict(zip(space.keys(),[max(space[s]) for s in space]))\n",
    "        self.min_val = dict(zip(space.keys(),[min(space[s]) for s in space]))\n",
    "        \n",
    "    #Busca pelo espaço hiperparamétrico\n",
    "    def fit_tuned(self):\n",
    "        \n",
    "        time_begin = time.time()\n",
    "        self.evolucao()\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_tuned = time.time() - time_begin\n",
    "        \n",
    "        #Pontuação \n",
    "        self.score_tuned = self.pontos_max\n",
    "        \n",
    "        #Melhores hiperparâmetros\n",
    "        #self.best_hp = self.model_tuned.best_params_\n",
    "    \n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #Dados de treino\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        #Espaço hiperparamétrico\n",
    "        self.getHP() \n",
    "        self.dict_ = list(self.hyp)\n",
    "        self.space = list(self.hyp.values())\n",
    "        self.max_val = dict(zip(self.hyp.keys(),[max(self.hyp[s]) for s in self.hyp]))\n",
    "        self.min_val = dict(zip(self.hyp.keys(),[min(self.hyp[s]) for s in self.hyp]))\n",
    "        \n",
    "        #Funções de treinamento\n",
    "        self.fit_default()\n",
    "        self.fit_tuned()\n",
    "        \n",
    "        #Pontuações relativas\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        \n",
    "        #Relatório\n",
    "        self.report()\n",
    "        \n",
    "        \n",
    "    #Relatório\n",
    "    def report(self):\n",
    "        print(\"Genetic Optimization Report\")\n",
    "        Otimizacao.report(self)\n",
    "\n",
    "    #Definindo população inicial\n",
    "    def set_pop(self):\n",
    "        \n",
    "        individuos = []\n",
    "    \n",
    "        for p in range(self.pop):\n",
    "            cromossomo = []\n",
    "            for gene in self.space:\n",
    "                cromossomo.append(random.choice(gene))\n",
    "\n",
    "            individuos.append(cromossomo)\n",
    "\n",
    "        return individuos\n",
    "    \n",
    "    #Definindo tipos\n",
    "    def types_genes(self):\n",
    "        #Armazenando tipos\n",
    "        self.types = [type(g[0]) for g in self.space]\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    #Ordenar pontos e cromossomos\n",
    "    def ordena (self, pontos, cromo):\n",
    "        zipped = zip(pontos, cromo)\n",
    "\n",
    "        ordenados = sorted(zipped)\n",
    "\n",
    "        pontos_ord = []\n",
    "        cromo_ord = []\n",
    "        for p, c in ordenados:\n",
    "\n",
    "            pontos_ord.append(p)\n",
    "            cromo_ord.append(c)\n",
    "\n",
    "        return pontos_ord, cromo_ord\n",
    "    \n",
    "    #Mutações\n",
    "    def mutacao(self, gf, gene):\n",
    "        #gerando taxa de mutação utilizando gaussiana de desvio 0.1\n",
    "        rate = np.random.normal(1, 0.1)\n",
    "        \n",
    "        if self.types[gene] is type(0): #int\n",
    "            gf = int(gf * rate)\n",
    "            if gf > self.max_val[self.dict_[gene]]:\n",
    "                gf = self.max_val[self.dict_[gene]]\n",
    "                \n",
    "            elif gf < self.min_val[self.dict_[gene]]:\n",
    "                gf = self.min_val[self.dict_[gene]]\n",
    "\n",
    "        elif self.types[gene] is type(0.0): #float\n",
    "            gf = round(gf * rate, 3)\n",
    "            if gf > self.max_val[self.dict_[gene]]:\n",
    "                gf = self.max_val[self.dict_[gene]]\n",
    "                \n",
    "            elif gf < self.min_val[self.dict_[gene]]:\n",
    "                gf = self.min_val[self.dict_[gene]]\n",
    "\n",
    "        elif self.types[gene] is type('0'): #string\n",
    "            gf = gf\n",
    "\n",
    "        return gf\n",
    "    \n",
    "    #Fazendo cruzamentos\n",
    "    def crossover(self, cromo_, pesos):\n",
    "        nova_geracao = []\n",
    "        for c in range (self.pop):\n",
    "            pai = random.choices(cromo_, weights=pesos)[0]\n",
    "            id_pai = cromo_.index(pai)\n",
    "\n",
    "            #Se houver mais de 1 cromossomo para a reprodução os pais devem ser diferentes\n",
    "            if len(cromo_) > 1:\n",
    "                cromo_.pop(id_pai)\n",
    "                pesos.pop(id_pai)\n",
    "\n",
    "            mae = random.choices(cromo_, weights=pesos)[0]\n",
    "\n",
    "            filho = []\n",
    "            for gene in range(len(pai)):\n",
    "                gp = pai[gene]\n",
    "                gm = mae[gene]\n",
    "                gf = random.choice([gp, gm])\n",
    "                \n",
    "                #Adicionando mutação\n",
    "                gf = self.mutacao(gf, gene)\n",
    "\n",
    "                filho.append(gf)\n",
    "\n",
    "            nova_geracao.append(filho)\n",
    "\n",
    "        return nova_geracao\n",
    "    \n",
    "    #Função de parada - Se a maior pontuação e o melhor cromossomo não alterararem por 5 gerações seguidas\n",
    "    def stop(self, cromos, pontos):\n",
    "        \n",
    "        equal = 0\n",
    "        \n",
    "        if len(self.top_cromos) < 5:\n",
    "            self.top_pontos.append(pontos[-1])\n",
    "            self.top_cromos.append(cromos[-1])\n",
    "            \n",
    "        else:\n",
    "            #verificar se o maior ponto é maior que o top\n",
    "            if pontos[-1] > min(self.top_pontos):\n",
    "                #apagar a menor pontuação\n",
    "                minimo = min(self.top_pontos)\n",
    "                min_id = self.top_pontos.index(minimo)\n",
    "                self.top_pontos.pop(min_id)\n",
    "                self.top_cromos.pop(min_id)\n",
    "                \n",
    "                #adicionar cromossomo e pontuações atuais\n",
    "                self.top_pontos.append(pontos[-1])\n",
    "                self.top_cromos.append(cromos[-1])\n",
    "            \n",
    "            #Verificar se os três melhores cromossomos são iguais\n",
    "            #Se forem iguais significa que não está atualizando, ou seja, pode parar\n",
    "            for cr in self.top_cromos:\n",
    "                if cr  == self.top_cromos [0]:\n",
    "                    equal += 1\n",
    "                    \n",
    "        #Todos valores iguais\n",
    "        if equal == 5:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "                \n",
    "            \n",
    "    #Obtendo resultado    \n",
    "    def obj(self, cr):\n",
    "        result = []\n",
    "        size = len(cr[0]) #quantidade de genes\n",
    "        for cromos in cr:\n",
    "            \n",
    "            modelo = self.getModel(cromos)\n",
    "            \n",
    "            modelo.fit(X_train, y_train)\n",
    "            res = modelo.score(X_test, y_test)\n",
    "\n",
    "            if res > self.max_pontos:\n",
    "                res = self.max_pontos - (res - self.max_pontos)\n",
    "\n",
    "            #print(res)\n",
    "            res = round(res, 3)\n",
    "            result.append(res)\n",
    "\n",
    "        return result    \n",
    "    \n",
    "    #Pegando modelo\n",
    "    def getModel(self):\n",
    "        return 0\n",
    "    \n",
    "    #Função da evolução\n",
    "    def evolucao(self):\n",
    "        self.types_genes()\n",
    "        self.cromo = self.set_pop()\n",
    "        self.parar = False\n",
    "        for ger in range(self.geracoes):\n",
    "            \n",
    "            if ger == 0:\n",
    "                self.pontos = self.obj(self.cromo)\n",
    "                self.pontos_max = max(self.pontos)\n",
    "                self.id_max = self.pontos.index(self.pontos_max)\n",
    "                self.vencedor = self.cromo[self.id_max]\n",
    "            \n",
    "            else:\n",
    "                self.cromo = self.cromo_ord\n",
    "                self.pontos = self.pontos_ord\n",
    "            \n",
    "            #Calculando pontuação\n",
    "            print(\"GERAÇÃO: \",ger)\n",
    "            print(\"Cromossomos: \",self.cromo)\n",
    "            print(\"Pontuações: \", self.pontos)\n",
    "\n",
    "            self.final_pont_max.append(max(self.pontos))\n",
    "\n",
    "            #Atualizando cromossomo vencedor\n",
    "            if(max(self.pontos) > self.pontos_max):\n",
    "                self.pontos_max = max(self.pontos)\n",
    "                self.id_max = self.pontos.index(self.pontos_max)\n",
    "                self.vencedor = self.cromo[self.id_max]\n",
    "\n",
    "            #Organizar listas de acordo com a pontuação\n",
    "            self.pontos_ord, self.cromo_ord = self.ordena(self.pontos, self.cromo)\n",
    "                \n",
    "            #Guardando 20% dos melhores para, além de serem pais, serem utilizados na nova geração\n",
    "            self.master = self.cromo_ord[int(math.floor(len(self.cromo_ord)*0.8)):]\n",
    "\n",
    "            #print(taxa)\n",
    "            #self.ponto_cut, self.cromo_cut = self.limiar(self.pontos_ord, self.cromo_ord)\n",
    "            self.ponto_cut, self.cromo_cut = self.pontos_ord, self.cromo_ord\n",
    "            \n",
    "            #Definindo pesos para os cromossomos\n",
    "            self.pesos = [i/self.max_pontos for i in self.pontos_ord]\n",
    "\n",
    "            #Crossover\n",
    "            self.geracao = self.crossover(self.cromo_ord, self.pesos)\n",
    "\n",
    "            #Adicionando melhores da geração anterior\n",
    "            for m in self.master:\n",
    "                self.geracao.append(m)\n",
    "                \n",
    "            #deletando os 20% piores\n",
    "            self.pontos = self.obj(self.geracao)\n",
    "            self.pontos_ord, self.cromo_ord = self.ordena(self.pontos, self.geracao)\n",
    "            self.cromo_ord = self.cromo_ord[int(math.floor(len(self.cromo_ord)*0.2)):]\n",
    "            self.pontos_ord = self.pontos_ord[int(math.floor(len(self.pontos_ord)*0.2)):]\n",
    "\n",
    "            print(\"--------\")\n",
    "            ##self.parar = self.stop(self.cromo_ord, self.pontos_ord)\n",
    "            self.parar = 0\n",
    "            if self.parar:\n",
    "                #Calculando pontuação\n",
    "                print(\"FINAL: \")\n",
    "                print(\"Cromossomos: \",self.cromo_ord)\n",
    "                print(\"Pontuações: \", self.pontos_ord)\n",
    "\n",
    "                self.final_pont_max.append(max(self.pontos_ord))\n",
    "\n",
    "                #Atualizando cromossomo vencedor\n",
    "                self.pontos_max = max(self.pontos_ord)\n",
    "                self.id_max = self.pontos.index(self.pontos_max)\n",
    "                self.vencedor = self.cromo_ord[self.id_max]\n",
    "                break;\n",
    "\n",
    "        print(\"Melhor pontuação: \", self.pontos_max)\n",
    "        print(\"Melhor cromossomo: \", self.vencedor)\n",
    "        print(\"Numero de gerações: \", (ger+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4qSgsoCMsHo4"
   },
   "outputs": [],
   "source": [
    "class GeneticSearchSVM(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"SVM\"\n",
    "        self.model = SVR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        kernel = ['rbf','linear']\n",
    "        C = (np.arange(10,100)/100).tolist() #0.1 - 0.99\n",
    "        epsilon = (np.arange(1,1000)/1000).tolist() #0.001 - 0.999\n",
    "        \n",
    "        self.hyp = {'kernel': kernel, 'C':C, 'epsilon':epsilon}\n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        kernel = cromos[self.dict_.index(\"kernel\")]\n",
    "        C = cromos[self.dict_.index('C')]\n",
    "        epsilon = cromos[self.dict_.index('epsilon')]\n",
    "\n",
    "        modelo = SVR(kernel = kernel, C = C, epsilon = epsilon)\n",
    "\n",
    "        return modelo\n",
    "    \n",
    "class GeneticSearchKNN(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"KNN\"\n",
    "        self.model = KNR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_n = (np.arange(5,20)).tolist() #de 5 até 20\n",
    "        weights = ['uniform','distance']\n",
    "        p = [1,2]\n",
    "        \n",
    "        self.hyp = {'n_neighbors':n_n, 'weights':weights, 'p':p }\n",
    "        \n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        n_n = cromos[self.dict_.index(\"n_neighbors\")]\n",
    "        weights = cromos[self.dict_.index('weights')]\n",
    "        p = cromos[self.dict_.index('p')]\n",
    "\n",
    "        modelo = KNR(n_neighbors = n_n, weights = weights, p = p)\n",
    "\n",
    "        return modelo\n",
    "    \n",
    "class GeneticSearchDT(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"DT\"\n",
    "        self.model = DecisionTreeRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        max_feat = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "        max_depth = (np.arange(10,100)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        spliter = ['best']\n",
    "        \n",
    "        self.hyp = {'min_samples_split':min_s_split, 'max_features':max_feat, 'max_depth':max_depth, \n",
    "        'criterion':criterion, 'splitter':spliter, 'min_samples_leaf': min_s_leaf}\n",
    "        \n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        min_s_split = cromos[self.dict_.index(\"min_samples_split\")]\n",
    "        max_feat = cromos[self.dict_.index('max_features')]\n",
    "        max_depth = cromos[self.dict_.index('max_depth')]\n",
    "        criterion = cromos[self.dict_.index('criterion')]\n",
    "        spliter = cromos[self.dict_.index('splitter')]\n",
    "        min_s_leaf = cromos[self.dict_.index('min_samples_leaf')]\n",
    "\n",
    "\n",
    "        modelo = DecisionTreeRegressor(min_samples_split = min_s_split, max_features = max_feat,\n",
    "                                      max_depth = max_depth, criterion = criterion,\n",
    "                                      splitter = spliter, min_samples_leaf= min_s_leaf)\n",
    "\n",
    "        return modelo\n",
    "    \n",
    "class GeneticSearchRF(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"RF\"\n",
    "        self.model = RandomForestRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        max_feat = (np.arange(2,10)/10).tolist() #0.2 - 0.9\n",
    "        criterion = ['mse','mae']\n",
    "        max_dpt = (np.arange(10,100)).tolist() #10 - 100\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        max_samp = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "        oob = [True,False]\n",
    "\n",
    "        \n",
    "        self.hyp = {'n_estimators' : n_est, 'criterion' : criterion, 'max_depth' : max_dpt, \n",
    "         'min_samples_split' : min_s_split,'min_samples_leaf' : min_s_leaf, 'max_samples' : max_samp,\n",
    "         'max_features' :  max_feat, 'oob_score' : oob}\n",
    "        \n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        n_est = cromos[self.dict_.index(\"n_estimators\")]\n",
    "        min_s_split = cromos[self.dict_.index('min_samples_split')]\n",
    "        max_feat = cromos[self.dict_.index('max_features')]\n",
    "        criterion = cromos[self.dict_.index('criterion')]\n",
    "        max_dpt = cromos[self.dict_.index('max_depth')]\n",
    "        min_s_leaf = cromos[self.dict_.index('min_samples_leaf')]\n",
    "        max_samp = cromos[self.dict_.index('max_samples')]\n",
    "        oob = cromos[self.dict_.index('oob_score')]\n",
    "\n",
    "\n",
    "        modelo = RandomForestRegressor(n_estimators = n_est, criterion = criterion,\n",
    "                                      max_depth = max_dpt, min_samples_split = min_s_split,\n",
    "                                      min_samples_leaf = min_s_leaf, max_features = max_feat,\n",
    "                                      oob_score = oob, max_samples = max_samp)\n",
    "\n",
    "        return modelo\n",
    "\n",
    "class GeneticSearchADB(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"ADB\"\n",
    "        self.model = AdaBoostRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        lr = (np.arange(1,1000)/1000).tolist() #0.001 - 0.999\n",
    "        loss = ['linear','exponential','square']\n",
    "        \n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate': lr, 'loss':loss}\n",
    "        \n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        n_est = cromos[self.dict_.index(\"n_estimators\")]\n",
    "        lr = cromos[self.dict_.index('learning_rate')]\n",
    "        loss = cromos[self.dict_.index('loss')]            \n",
    "\n",
    "        modelo = AdaBoostRegressor(n_estimators = n_est, learning_rate = lr,\n",
    "                                          loss = loss)\n",
    "        return modelo\n",
    "    \n",
    "class GeneticSearchGDB(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"GDB\"\n",
    "        self.model = GradientBoostingRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        min_s_split = (np.arange(2,21)).tolist() #1 - 20\n",
    "        sub = (np.arange(5,10)/10).tolist() #0.5 - 0.9\n",
    "        lr = (np.arange(5,1000)/1000).tolist() # 0.005 - 0.999\n",
    "        criterion = ['mse','friedman_mse','mae']\n",
    "        min_s_leaf = (np.arange(5,21)/100).tolist() #0.05 - 0.2\n",
    "        max_feat = (np.arange(2,10)/10).tolist() #0.2 - 0.9\n",
    "        max_dpt = (np.arange(10,100)).tolist() #10 - 100\n",
    "        alpha = (np.arange(50,100)/100).tolist() #0.5 - 0.99\n",
    "        \n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate':lr, 'min_samples_split': min_s_split, \n",
    "                    'criterion': criterion, 'min_samples_leaf': min_s_leaf, 'max_depth':max_dpt, 'subsample':sub, 'max_features': max_feat, \n",
    "                    'loss': ['ls', 'lad','huber', 'quantile'], 'alpha': alpha}\n",
    "\n",
    "        \n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        n_est = cromos[self.dict_.index(\"n_estimators\")]\n",
    "        lr = cromos[self.dict_.index('learning_rate')]\n",
    "        min_s_split = cromos[self.dict_.index('min_samples_split')]\n",
    "        criterion = cromos[self.dict_.index('criterion')]\n",
    "        min_s_leaf = cromos[self.dict_.index('min_samples_leaf')]\n",
    "        max_dpt = cromos[self.dict_.index('max_depth')]\n",
    "        sub = cromos[self.dict_.index('subsample')]\n",
    "        max_feat = cromos[self.dict_.index('max_features')]\n",
    "        loss = cromos[self.dict_.index('loss')]\n",
    "        alpha = cromos[self.dict_.index('alpha')]\n",
    "\n",
    "        modelo = GradientBoostingRegressor(n_estimators = n_est, learning_rate = lr,\n",
    "                                      min_samples_split = min_s_split, criterion = criterion,\n",
    "                                      min_samples_leaf = min_s_leaf, max_depth =max_dpt,\n",
    "                                      subsample = sub, max_features = max_feat,\n",
    "                                      loss =loss, alpha = alpha)\n",
    "\n",
    "        return modelo\n",
    "    \n",
    "class GeneticSearchXGB(GeneticSearch):\n",
    "    \n",
    "    def __init__ (self, n_geracoes=10, populacao=10, space = {}):\n",
    "        GeneticSearch.__init__(self, n_geracoes, populacao, {})\n",
    "        self.name = \"XGB\"\n",
    "        self.model = XGBRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        n_est = (np.arange(50,751)).tolist() #50 - 750\n",
    "        lr = (np.arange(1,100)/100).tolist() # 0.01 - 0.99\n",
    "        bst = ['gbtree','gblinear','dart']\n",
    "\n",
    "        self.hyp = {'n_estimators':n_est, 'learning_rate':lr,'booster':bst}\n",
    "        \n",
    "        \n",
    "    def getModel(self, cromos):\n",
    "        \n",
    "        n_est = cromos[self.dict_.index(\"n_estimators\")]\n",
    "        lr = cromos[self.dict_.index('learning_rate')]\n",
    "        bst = cromos[self.dict_.index('booster')]\n",
    "\n",
    "        modelo = XGBRegressor(n_estimators = n_est, learning_rate = lr, booster = bst)\n",
    "            \n",
    "        return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cux3slZmsHof"
   },
   "source": [
    "### PBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mSXTPADcsHou"
   },
   "outputs": [],
   "source": [
    "class PBTSearch(Otimizacao):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Otimizacao.__init__(self)\n",
    "        self.pop = 10\n",
    "        self.gen = 10\n",
    "        \n",
    "    #Busca pelo espaço hiperparamétrico\n",
    "    def fit_tuned(self):\n",
    "        \n",
    "        time_begin = time.time()\n",
    "        self.PBTObjective()\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_tuned = time.time() - time_begin\n",
    "        \n",
    "        #Pontuação \n",
    "        self.score_tuned = self.model_tuned.score(self.X_test, self.y_test)\n",
    "        \n",
    "        #Melhores hiperparâmetros\n",
    "        #self.best_hp = self.model_tuned.best_params_\n",
    "    \n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #Dados de treino\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        #Espaço hiperparamétrico\n",
    "        self.getHP()\n",
    "        \n",
    "        #Preparando PBT\n",
    "        self.algorithm = sherpa.algorithms.PopulationBasedTraining(population_size=self.pop,\n",
    "                                                                  num_generations=self.gen, perturbation_factors=(0.8, 1.2))\n",
    "\n",
    "        self.study = sherpa.Study(parameters=self.hyp, algorithm=self.algorithm, disable_dashboard = True, lower_is_better=False)\n",
    "        \n",
    "        #Funções de treinamento\n",
    "        self.fit_default()\n",
    "        self.fit_tuned()\n",
    "        \n",
    "        #Pontuações relativas\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        \n",
    "        #Relatório\n",
    "        self.report()\n",
    "        \n",
    "        \n",
    "    #Relatório\n",
    "    def report(self):\n",
    "        print(\"Population Based Training Report\")\n",
    "        Otimizacao.report(self)\n",
    "        \n",
    "    #Função de otimização\n",
    "    def PBTObjective(self):\n",
    "        for trial in self.study:\n",
    "            generation = trial.parameters['generation']\n",
    "\n",
    "            print(\"-\"*100)\n",
    "            print(\"Generation {}\".format(generation))\n",
    "            print(\"Trial \", trial.id, \" with parameters \", trial.parameters)\n",
    "            \n",
    "            self.model_tuned = self.PBTDefineModel(trial)\n",
    "\n",
    "            self.model_tuned.fit(self.X_train, self.y_train)\n",
    "            self.score_tuned_ = self.model_tuned.score(self.X_test, self.y_test)\n",
    "\n",
    "            print(\"Validation accuracy: \", self.score_tuned_)\n",
    "            self.study.add_observation(trial=trial, iteration=generation,\n",
    "                                  objective=self.score_tuned_)\n",
    "            self.study.finalize(trial=trial)\n",
    "        return self.study.get_best_result()\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "# Support vector machine\n",
    "class PBTSearchSVM(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"SVM\"\n",
    "        self.model = SVR()\n",
    "        \n",
    "    def getHP(self):\n",
    "\n",
    "        self.hyp = {sherpa.Choice('kernel',['rbf','linear']),\n",
    "                    sherpa.Continuous('C',[0.1,0.99]),\n",
    "                    sherpa.Continuous('epsilon',[0.001,0.999])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        \n",
    "        return SVR(C=trial.parameters['C'], epsilon = trial.parameters['epsilon'], kernel=trial.parameters['kernel'])\n",
    "        \n",
    "        \n",
    "#KNN\n",
    "class PBTSearchKNN(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"KNN\"\n",
    "        self.model = KNR()\n",
    "        \n",
    "    def getHP(self):\n",
    "        self.hyp = {sherpa.Discrete('n_neighbors',[5,13]),\n",
    "                    sherpa.Choice('weights',['uniform','distance']),\n",
    "                    sherpa.Discrete('p',[1,2])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        \n",
    "        return KNR(n_neighbors = trial.parameters['n_neighbors'] ,weights = trial.parameters['weights'] ,p = trial.parameters['p'])\n",
    "        \n",
    "        \n",
    "#Decision Tree\n",
    "class PBTSearchDT(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"Decision Tree\"\n",
    "        self.model = DecisionTreeRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        self.hyp = {sherpa.Discrete('min_samples_split',[2,20]),\n",
    "                    sherpa.Continuous('max_features',[0.5,0.99]),\n",
    "                    sherpa.Discrete('max_depth',[10,100]), \n",
    "                    sherpa.Choice('criterion',['mse','friedman_mse','mae']),\n",
    "                    sherpa.Choice('splitter',['best']),\n",
    "                    sherpa.Continuous('min_samples_leaf',[0.05,0.2])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        return  DecisionTreeRegressor(min_samples_split = trial.parameters['min_samples_split'],\n",
    "                                             max_features = trial.parameters['max_features'],\n",
    "                                             max_depth = trial.parameters['max_depth'],\n",
    "                                             criterion = trial.parameters['criterion'],\n",
    "                                             splitter = trial.parameters['splitter'],\n",
    "                                             min_samples_leaf = trial.parameters['min_samples_leaf'])\n",
    "        \n",
    "        \n",
    "#Random Forest\n",
    "class PBTSearchRF(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"Random Forest\"\n",
    "        self.model = RandomForestRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        self.hyp = {sherpa.Discrete('n_estimators',[50,750]), \n",
    "                    sherpa.Discrete('min_samples_split',[2,20]), \n",
    "                    sherpa.Continuous('max_features',[0.2,0.9]), \n",
    "                    sherpa.Discrete('max_depth',[10,100]),\n",
    "                    sherpa.Continuous('min_samples_leaf',[0.05,0.2]), \n",
    "                    sherpa.Continuous('max_samples',[0.5,0.99]), \n",
    "                    sherpa.Choice('criterion',['mse','mae']), \n",
    "                    sherpa.Choice('oob_score',[True,False])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        return RandomForestRegressor(n_estimators = trial.parameters['n_estimators'],\n",
    "                                              min_samples_split = trial.parameters['min_samples_split'],\n",
    "                                              max_features = trial.parameters['max_features'],\n",
    "                                              max_depth = trial.parameters['max_depth'],\n",
    "                                              min_samples_leaf = trial.parameters['min_samples_leaf'],\n",
    "                                              max_samples = trial.parameters['max_samples'],\n",
    "                                              criterion = trial.parameters['criterion'],\n",
    "                                              oob_score = trial.parameters['oob_score'])\n",
    "        \n",
    "        \n",
    "#Ada Boost\n",
    "class PBTSearchADB(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"AdaBoost\"\n",
    "        self.model = AdaBoostRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        self.hyp = {sherpa.Discrete('n_estimators',[50,750]),\n",
    "                    sherpa.Continuous('learning_rate',[0.001,0.999]),\n",
    "                    sherpa.Choice('loss',['linear','exponential','square'])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        return AdaBoostRegressor(n_estimators = trial.parameters['n_estimators'],\n",
    "                                          learning_rate = trial.parameters['learning_rate'],\n",
    "                                          loss = trial.parameters['loss'])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "#Gradient Boosting\n",
    "class PBTSearchGDB(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"Gradient Boosting\"\n",
    "        self.model = GradientBoostingRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        self.hyp = {sherpa.Discrete('n_estimators',[50,750]), \n",
    "                    sherpa.Continuous('learning_rate',[0.005,0.999]), \n",
    "                    sherpa.Discrete('min_samples_split',[2,20]), \n",
    "                    sherpa.Choice('criterion',['mse','friedman_mse','mae']), \n",
    "                    sherpa.Continuous('min_samples_leaf',[0.05,0.2]), \n",
    "                    sherpa.Discrete('max_depth',[10,100]), \n",
    "                    sherpa.Continuous('subsample',[0.5,0.9]), \n",
    "                    sherpa.Continuous('max_features',[0.2,0.9]), \n",
    "                    sherpa.Choice('loss',['ls', 'lad','huber', 'quantile']), \n",
    "                    sherpa.Continuous('alpha',[0.5,0.99])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        return GradientBoostingRegressor(n_estimators = trial.parameters['n_estimators'],\n",
    "                                                  learning_rate = trial.parameters['learning_rate'],\n",
    "                                                  min_samples_split = trial.parameters['min_samples_split'],\n",
    "                                                  criterion = trial.parameters['criterion'],\n",
    "                                                  min_samples_leaf = trial.parameters['min_samples_leaf'],\n",
    "                                                  max_depth = trial.parameters['max_depth'],\n",
    "                                                  subsample = trial.parameters['subsample'],\n",
    "                                                  max_features = trial.parameters['max_features'],\n",
    "                                                  loss = trial.parameters['loss'],\n",
    "                                                  alpha = trial.parameters['alpha'])\n",
    "        \n",
    "        \n",
    "#XGBoost\n",
    "class PBTSearchXGB(PBTSearch):\n",
    "    \n",
    "    def __init__(self):\n",
    "        PBTSearch.__init__(self)\n",
    "        self.name = \"XGBoost\"\n",
    "        self.model = XGBRegressor()\n",
    "        \n",
    "    def getHP(self):\n",
    "        self.hyp = {sherpa.Discrete('n_estimators',[50,750]), \n",
    "                    sherpa.Continuous('learning_rate',[0.01,0.99]),\n",
    "                    sherpa.Choice('booster',['gbtree','gblinear','dart'])}\n",
    "        \n",
    "    def PBTDefineModel(self, trial):\n",
    "        \n",
    "        return XGBRegressor(n_estimators = trial.parameters['n_estimators'],\n",
    "                                    learning_rate = trial.parameters['learning_rate'],\n",
    "                                    booster = trial.parameters['booster'])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDSAtq4EH6pz"
   },
   "source": [
    "### Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jSHzSQ3XDeUW"
   },
   "outputs": [],
   "source": [
    "class OtimizacaoNN():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.time = 0\n",
    "        self.time_default = 0\n",
    "        self.time_tuned = 0\n",
    "        self.score = 0\n",
    "        self.score_default = 0\n",
    "        self.score_tuned = 0\n",
    "        self.model = None\n",
    "        self.model_tuned = None\n",
    "        self.getHP()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "\n",
    "    def report(self):\n",
    "        print(\"Modelo: \", self.name)\n",
    "        print(\"--Pontuações--\")\n",
    "        print(\"Padrão: \", self.score_default)\n",
    "        print(\"Ajustado: \", self.score_tuned)\n",
    "        print(\"Relativo: \", self.score)\n",
    "        print(\"--Tempos--\")\n",
    "        print(\"Padrão: \", self.time_default)\n",
    "        print(\"Ajustado: \", self.time_tuned)\n",
    "        print(\"Relativo: \", self.time)\n",
    "        #print(\"Melhor configuração: \", self.best_hp)\n",
    "\n",
    "    def setModel(self, optimizer = 'adam', activation='relu', dropout = 0.0, hidden = 1, n_first = 50, n_last = 5):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        nodes = self.findNodes(hidden, n_first, n_last)\n",
    "\n",
    "        for i in range(0, hidden+1):\n",
    "            if i==0:\n",
    "                model.add(Dense(n_first, activation = activation))\n",
    "            else:\n",
    "                model.add(Dense(nodes[i], activation = activation))\n",
    "                model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(loss='mse', optimizer = optimizer)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def findNodes(self, hidden, n_first, n_last):\n",
    "        \n",
    "        layers = []\n",
    "        if hidden == 1:\n",
    "            increment = (n_first + n_last) / 2\n",
    "        else:\n",
    "            increment = (n_last - n_first) / hidden\n",
    "\n",
    "        layers.append(n_first)\n",
    "\n",
    "        nodes = n_first\n",
    "\n",
    "        for i in range(0, hidden):\n",
    "            nodes = nodes + increment\n",
    "            layers.append(math.ceil(nodes))\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def getHP(self):\n",
    "        batch_size = [16, 32, 64, 128]\n",
    "        epochs = [5,10,15,20]\n",
    "        optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "        activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "        dropout_rate = [0.0, 0.1, 0.2, 0.3]\n",
    "        node_first = [50, 75, 100]\n",
    "        node_last = [5, 7, 10]\n",
    "        hidden = [2,3,4]\n",
    "\n",
    "        self.hyp = dict(batch_size = batch_size,\n",
    "                        epochs = epochs,\n",
    "                        optimizer = optimizer, \n",
    "                        activation=activation, \n",
    "                        dropout = dropout_rate,\n",
    "                        hidden = hidden,\n",
    "                        n_first = node_first,\n",
    "                        n_last = node_last)\n",
    "        \n",
    "    def fit_default(self):\n",
    "\n",
    "        time_begin = time.time()\n",
    "        self.model = self.setModel()\n",
    "        self.model.fit(self.X_train, self.y_train, batch_size = 32, epochs = 2)\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_default = (time.time() - time_begin)\n",
    "        \n",
    "        #Pontuação\n",
    "        self.score_default = self.getScore(self.model)\n",
    "\n",
    "    # Recolhendo pontuação R2\n",
    "    def getScore(self, model):\n",
    "\n",
    "        y_hat = model.predict(self.X_test)\n",
    "        \n",
    "        #se contem valores nan deve zerar\n",
    "        if True in np.isnan(y_hat):\n",
    "            y_hat = np.zeros([len(y_hat),1])\n",
    "\n",
    "        return r2_score(self.y_test, y_hat)\n",
    "\n",
    "    def fit_tuned(self):\n",
    "\n",
    "        time_begin = time.time()\n",
    "        self.result = self.model_tuned.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_tuned = (time.time() - time_begin)\n",
    "        \n",
    "        #Pontuação\n",
    "        self.score_tuned = self.getScore(self.result)\n",
    "        \n",
    "    def transformData(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        X_train = np.array(X_train)\n",
    "        self.X_train = X_train.reshape(X_train.shape[0],X_train.shape[1], 1)\n",
    "        \n",
    "        X_test = np.array(X_test)\n",
    "        self.X_test = X_test.reshape(X_test.shape[0],X_test.shape[1], 1)\n",
    "        \n",
    "        self.y_train = np.array(y_train)\n",
    "        self.y_test = np.array(y_test)\n",
    "        \n",
    "    def getResult(self):\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "\n",
    "class GridSearchNN(OtimizacaoNN):\n",
    "\n",
    "    def __init__(self):\n",
    "        OtimizacaoNN.__init__(self)\n",
    "        self.name = \"Grid - Neural Network\"\n",
    "\n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "\n",
    "        self.transformData(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        model_wrapped = KerasRegressor(build_fn = self.setModel, verbose = 1)\n",
    "\n",
    "        self.model_tuned = GridSearchCV(estimator =  model_wrapped, \n",
    "                                  param_grid = self.hyp, \n",
    "                                  cv = 3)\n",
    "\n",
    "        #Treinando modelos\n",
    "        self.fit_tuned()\n",
    "        self.fit_default()\n",
    "\n",
    "        #Dados Relativos\n",
    "        self.getResult()\n",
    "\n",
    "        self.best_hp = self.result.best_params_     \n",
    "\n",
    "        self.report()\n",
    "        print(\"Melhor configuração: \", self.best_hp)\n",
    "\n",
    "class RandomSearchNN(OtimizacaoNN):\n",
    "\n",
    "    def __init__(self):\n",
    "        OtimizacaoNN.__init__(self)\n",
    "        self.name = \"Random - Neural Network\"\n",
    "\n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "\n",
    "        self.transformData(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        model_wrapped = KerasRegressor(build_fn = self.setModel, verbose = 1)\n",
    "\n",
    "        self.model_tuned = RandomizedSearchCV(estimator =  model_wrapped, \n",
    "                                  param_distributions = self.hyp, n_iter = 60,\n",
    "                                  cv = 3)\n",
    "\n",
    "        #Treinando modelos\n",
    "        self.fit_tuned()\n",
    "        self.fit_default()\n",
    "\n",
    "        #Dados Relativos\n",
    "        self.getResult()\n",
    "\n",
    "        self.best_hp = self.result.best_params_     \n",
    "\n",
    "        self.report()\n",
    "        print(\"Melhor configuração: \", self.best_hp)\n",
    "\n",
    "class BayesianSearchNN(OtimizacaoNN):\n",
    "\n",
    "    def __init__(self):\n",
    "        OtimizacaoNN.__init__(self)\n",
    "        self.name = \"Bayesian - Neural Network\"\n",
    "\n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "\n",
    "        self.transformData(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        model_wrapped = KerasRegressor(build_fn = self.setModel, verbose = 1)\n",
    "\n",
    "        self.model_tuned = BayesSearchCV(estimator =  model_wrapped, \n",
    "                                         search_spaces = self.hyp, n_iter = 60, cv = 3, refit=True)\n",
    "\n",
    "        #Treinando modelos\n",
    "        self.fit_tuned()\n",
    "        self.fit_default()\n",
    "\n",
    "        #Dados Relativos\n",
    "        self.getResult()\n",
    "\n",
    "        self.best_hp = self.result.best_params_     \n",
    "\n",
    "        self.report()\n",
    "        print(\"Melhor configuração: \", self.best_hp)\n",
    "\n",
    "class PBTSearchNN(OtimizacaoNN):\n",
    "\n",
    "    def __init__(self):\n",
    "        OtimizacaoNN.__init__(self)\n",
    "        self.name = \"PBT - Neural Network\"\n",
    "\n",
    "    def getHP(self):\n",
    "        self.hyp = [sherpa.Choice('optimizer',['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']),\n",
    "                    sherpa.Choice('activation',['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']),\n",
    "                    sherpa.Discrete('neurons',[50, 75, 100]),\n",
    "                    sherpa.Discrete('final_layer',[5,7,10]),\n",
    "                    sherpa.Discrete('n_layers',[2,3,4,5]),\n",
    "                    sherpa.Discrete('epochs',[5,10,15,20]),\n",
    "                    sherpa.Discrete('batch_size',[16, 32,64,128]),\n",
    "                    sherpa.Continuous('dropout_rate',[0, 0.1, 0.2, 0.3])]\n",
    "                    \n",
    "\n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        #self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "\n",
    "        self.transformData(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        algorithm = sherpa.algorithms.PopulationBasedTraining(population_size=10,\n",
    "                                                      num_generations=10,\n",
    "                                                      perturbation_factors=(0.8, 1.2))\n",
    "        \n",
    "        study = sherpa.Study(parameters=self.hyp,\n",
    "                     algorithm=algorithm,\n",
    "                     disable_dashboard = True,\n",
    "                     lower_is_better=False)\n",
    "        \n",
    "        i = 0\n",
    "        ini = time.time()\n",
    "        for trial in study:\n",
    "            try:\n",
    "                generation = trial.parameters['generation']\n",
    "                load_from = trial.parameters['load_from']\n",
    "                optimizer = trial.parameters['optimizer']\n",
    "                activation = trial.parameters['activation']\n",
    "                n_layers = trial.parameters['n_layers']\n",
    "                final_layer = trial.parameters['final_layer']\n",
    "                neurons = trial.parameters['neurons']\n",
    "                epochs = trial.parameters['epochs']\n",
    "                drop = trial.parameters['dropout_rate']\n",
    "                batch = trial.parameters['batch_size']\n",
    "                \n",
    "\n",
    "                print(\"-\"*100)\n",
    "                print(\"Generation {}\".format(generation))\n",
    "\n",
    "\n",
    "                print(\"Creating new model with\\nOptimizer: \",optimizer,\"\\nActivation: \", activation)\n",
    "                print(\"N_Layers: \",n_layers,\"\\nNeurons: \", neurons,\"\\nN_last: \", final_layer,\"\\nEpochs: \", epochs,\n",
    "                    \"Dropout: \",drop\n",
    "                    )\n",
    "\n",
    "                layers = self.findNodes(n_layers, neurons, final_layer)\n",
    "                \n",
    "                # Create model\n",
    "                \n",
    "                model = Sequential()\n",
    "                \n",
    "                model.add(Flatten())\n",
    "                \n",
    "                for n in range(0, n_layers+1):\n",
    "                    if n == 0:\n",
    "                        model.add(Dense(neurons, activation = activation, input_dim=X_train.shape[1]))\n",
    "                    else:\n",
    "                        model.add(Dense(layers[n], activation = activation))\n",
    "                        model.add(Dropout(drop))\n",
    "                \n",
    "                model.add(Dense(1))\n",
    "                \n",
    "                model.compile(loss='mse',\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=[keras.metrics.MeanSquaredError()])\n",
    "\n",
    "\n",
    "                # Train model for one epoch\n",
    "                model.fit(X_train, y_train, epochs=epochs, batch_size = batch)\n",
    "                #loss, accuracy = model.evaluate(X_test, y_test)\n",
    "                score = self.getScore(model)\n",
    "                print(\"Validation accuracy: \", score)\n",
    "                study.add_observation(trial=trial, iteration=generation,\n",
    "                                    objective=score)\n",
    "                \n",
    "                try:\n",
    "                    study.finalize(trial=trial)\n",
    "                    print(\"---Finalizado---\")\n",
    "                except :\n",
    "                    print(\"---ERRO---\")\n",
    "                    i = i+1\n",
    "            except:\n",
    "                print(\"### Erro no modelo###\")\n",
    "                \n",
    "        print(i, \" erros\")\n",
    "        self.time_tuned = time.time() - ini\n",
    "\n",
    "        self.results = study.get_best_result()\n",
    "        self.score_tuned = self.results['Objective']\n",
    "\n",
    "        self.fit_default()\n",
    "\n",
    "        #Dados Relativos\n",
    "        self.getResult()   \n",
    "\n",
    "        self.report()\n",
    "        print(\"Melhor configuração: \", self.results)\n",
    "\n",
    "\n",
    "class GeneticSearchNN(OtimizacaoNN, GeneticSearch):\n",
    "\n",
    "    def __init__(self):\n",
    "        GeneticSearch.__init__(self, n_geracoes=10, populacao=10)\n",
    "        OtimizacaoNN.__init__(self)\n",
    "        self.name = \"Genetic - Neural Network\"\n",
    "\n",
    "    def getHP(self):\n",
    "        batch_size = [16, 32, 64, 128]\n",
    "        epochs = [5,10,15,20]\n",
    "        optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "        activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "        dropout_rate = [0.0, 0.1, 0.2, 0.3]\n",
    "        node_first = [50, 75, 100]\n",
    "        node_last = [5, 7, 10]\n",
    "        hidden = [2,3,4]\n",
    "        self.hyp = dict(batch_size = batch_size, epochs = epochs, optimizer = optimizer,\n",
    "                    activation = activation, dropout_rate = dropout_rate,\n",
    "                    node_first = node_first, node_last = node_last, hidden = hidden)\n",
    "\n",
    "\n",
    "    def obj(self, cr, idx = 0): #idx = 0 retorna o resultado, idx = 1 retorna o modelo\n",
    "        result = []\n",
    "        size = len(cr[0]) #quantidade de genes\n",
    "        for cromos in cr:\n",
    "    \n",
    "            self.batch_size = cromos[self.dict_.index(\"batch_size\")]\n",
    "            self.epochs = cromos[self.dict_.index('epochs')]\n",
    "            optimizer = cromos[self.dict_.index('optimizer')]\n",
    "            activation = cromos[self.dict_.index(\"activation\")]\n",
    "            dropout_rate = cromos[self.dict_.index(\"dropout_rate\")]\n",
    "            node_first = cromos[self.dict_.index(\"node_first\")]\n",
    "            node_last = cromos[self.dict_.index(\"node_last\")]\n",
    "            hidden = cromos[self.dict_.index(\"hidden\")]\n",
    "\n",
    "            modelo = self.setModel(optimizer = optimizer, activation=activation, \n",
    "                                   dropout = dropout_rate, hidden = hidden, \n",
    "                                   n_first = node_first, n_last = node_last)\n",
    "            \n",
    "            modelo.fit(X_train, y_train, epochs = self.epochs, batch_size = self.batch_size, verbose = 1)\n",
    "            \n",
    "            res = self.getScore(modelo)\n",
    "\n",
    "            #print(res)\n",
    "            res = round(res, 3)\n",
    "            if math.isnan(res):\n",
    "                res = -math.inf\n",
    "                \n",
    "            result.append(res)\n",
    "\n",
    "        if idx == 0:\n",
    "            return result\n",
    "        return modelo\n",
    "\n",
    "    #Busca pelo espaço hiperparamétrico\n",
    "    def fit_tuned(self):\n",
    "        \n",
    "        time_begin = time.time()\n",
    "        self.evolucao()\n",
    "        \n",
    "        #Tempo de treinamento\n",
    "        self.time_tuned = time.time() - time_begin\n",
    "        \n",
    "        #Pontuação \n",
    "        self.score_tuned = self.pontos_max\n",
    "\n",
    "    def search(self, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        #Dados de treino\n",
    "        #self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        self.transformData(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        #Espaço hiperparamétrico\n",
    "        self.getHP() \n",
    "        self.dict_ = list(self.hyp)\n",
    "        self.space = list(self.hyp.values())\n",
    "        self.max_val = dict(zip(self.hyp.keys(),[max(self.hyp[s]) for s in self.hyp]))\n",
    "        self.min_val = dict(zip(self.hyp.keys(),[min(self.hyp[s]) for s in self.hyp]))\n",
    "        \n",
    "        #Funções de treinamento\n",
    "        self.fit_default()\n",
    "        self.fit_tuned()\n",
    "        \n",
    "        #Pontuações relativas\n",
    "        self.time = self.time_tuned / self.time_default\n",
    "        self.score = self.score_tuned / self.score_default\n",
    "        \n",
    "        #Relatório\n",
    "        self.report()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36Qifd0D-Eau"
   },
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KTClZRkwuDB"
   },
   "outputs": [],
   "source": [
    "models = [[RandomSearchSVM(), RandomSearchKNN(), RandomSearchDT(), RandomSearchRF(), RandomSearchADB(),RandomSearchGDB(),RandomSearchXGB()],\n",
    "          [BayesianSearchSVM(), BayesianSearchKNN(), BayesianSearchDT(), BayesianSearchRF(), BayesianSearchADB(),BayesianSearchGDB(),BayesianSearchXGB()],\n",
    "          [PBTSearchSVM(), PBTSearchKNN(), PBTSearchDT(), PBTSearchRF(), PBTSearchADB(),PBTSearchGDB(),PBTSearchXGB()],\n",
    "          [GeneticSearchSVM(), GeneticSearchKNN(), GeneticSearchDT(), GeneticSearchRF(), GeneticSearchADB(),GeneticSearchGDB(),GeneticSearchXGB()]]\n",
    "\n",
    "opt = ['Random', 'Bayesian', 'PBT', 'Genetic']\n",
    "alg = ['SVM','KNN','DT','RF','ADB','GDB','XGB']\n",
    "names = []\n",
    "sc =[]\n",
    "scd=[]\n",
    "sct=[]\n",
    "tm = []\n",
    "tmt=[]\n",
    "\n",
    "for i,m1 in enumerate(models):\n",
    "  for j,m in enumerate(m1):\n",
    "    nome = str(opt[i]) + \" - \" + str(alg[j])\n",
    "    names.append(nome)\n",
    "    m.search(X_train, X_test, y_train, y_test)\n",
    "    sc.append(m.score)\n",
    "    scd.append(m.score_default)\n",
    "    sct.append(m.score_tuned)\n",
    "    tm.append(m.time)\n",
    "    tmt.append(m.time_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSZLQtcN1nuO"
   },
   "outputs": [],
   "source": [
    "for i,n in enumerate(names):\n",
    "  print(n)\n",
    "  print(\"Score default: \", scd[i])\n",
    "  print(\"Score tuned: \", sct[i])\n",
    "  print(\"Score : \", sc[i])\n",
    "  print(\"Time tuned: \", tmt[i])\n",
    "  print(\"Time: \", tm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "-JPoUCUD49Vd",
    "outputId": "0bbee146-1638-4576-e4b0-095f8a8a7d67"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = []\n",
    "for s in sc:\n",
    "  if s<1.0:\n",
    "    c.append('red')\n",
    "  else:\n",
    "    c.append('blue')\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(np.arange(len(sc)),sc, width=0.6, color = c)\n",
    "plt.hlines(1.0, 0, len(sc), colors='red')\n",
    "plt.xticks(np.arange(len(names)), names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "HRXT_IIi7lB8",
    "outputId": "748d1c80-d404-4e50-aec9-77920ce26390"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(np.arange(len(sc)),sct, width=0.6)\n",
    "plt.hlines(0.9, 0, len(sc), colors='red')\n",
    "plt.xticks(np.arange(len(names)), names, rotation=280)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T0UcSYMJiDw"
   },
   "source": [
    "### Resultados NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "P6fOo3bUHJrp"
   },
   "outputs": [],
   "source": [
    "randomNN = RandomSearchNN()\n",
    "bayesNN = BayesianSearchNN()\n",
    "geneticNN = GeneticSearchNN()\n",
    "pbtNN = PBTSearchNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "cgTWUujI0CYs",
    "outputId": "12853042-f7ad-4d82-e622-a35c43589496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32463.3887\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32262.2812\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32151.9746\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32108.9355\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32035.7441\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32025.1816\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31964.9844\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31941.6699\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31911.9688\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31893.5391\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31830.0410\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31827.6270\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 31796.0312\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 32940.921 - 0s 2ms/step - loss: 31760.7109\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31732.6035\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31743.0352\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 31703.6504\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31682.7539\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31638.3359\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31644.0645\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 31692.7910\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32814.4023\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32678.8965\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32603.1992\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32562.9902\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32527.0312\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32484.0371\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32449.6016\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32447.4570\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32408.0840\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32374.3340\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32373.9844\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32338.6445\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32326.4180\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32307.8574\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32299.2832\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32271.0566\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32251.1953\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32218.0938\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32212.5859\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32203.9902\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 32372.6270\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32710.1777\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32502.1582\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32363.2012\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32258.4258\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32211.7012\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32167.6562\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32085.8887\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32061.2480\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32001.6797\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31982.4258\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 31931.2227\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31897.3633\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31903.1562\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31862.9258\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 31825.0117\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 31809.4258\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31759.5254\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31761.8887\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31757.0938\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31697.2852\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 31432.6680\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 33064.2148\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 33047.8789\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33045.6484\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33040.5156\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33037.9766\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 33099.0078\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33092.7266\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 33088.6836\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33080.4531\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 33077.0195\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33071.8477\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D05EA5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D05EA5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 33266.4297\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33015.6406\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33010.5977\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33004.4766\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 33000.6523\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32999.3555\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D0682828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D0682828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 32732.1445\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32840.0078\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32721.0117\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32646.3242\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32604.6445\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32574.6855\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32548.1953\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32523.3184\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32499.0195\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32474.1094\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32446.5957\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32417.0645\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32385.0156\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32354.5703\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32329.4355\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32307.9629\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32287.4043\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32267.4863\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32248.3242\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32229.9805\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32211.7637\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D180B678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D180B678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 32267.1270\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 33025.6328\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 32746.3887\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32617.0410\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32545.4707\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32493.1406\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32448.0957\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32412.5039\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32384.3613\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32357.7598\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32332.0469\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32308.2148\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32287.1465\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32267.1504\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32247.5820\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32228.3027\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32209.3145\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32190.6270\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32172.1211\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32153.5352\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32135.4141\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D06820D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D06820D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 32316.1172\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32664.6270\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32544.9160\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32465.3535\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32405.8535\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32358.3223\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32318.3418\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32282.0195\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32247.9219\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32217.5996\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32190.9258\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32166.4805\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32143.4590\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32121.3691\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32099.7832\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32078.9883\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32059.0273\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32039.6641\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 32020.4902\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32001.6328\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 31983.0195\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D178E438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D178E438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 31711.7383\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17123.2930\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10245.1152\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7274.7812\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5578.2988\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3986.9705\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2925.5466\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2765.0273\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2403.6672\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2310.4465\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2399.1094\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2569.0496\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2252.1428\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2101.2510\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2457.8159\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2504.2195\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2543.3679\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2208.5342\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2071.8818\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2323.7463\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1965.2277\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D178E708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D178E708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 242.6380\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 29013.9199\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 20809.1055\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15855.1416\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 11110.8311\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6919.9258\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4361.6182\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2889.5496\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2644.2810\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2526.4734\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2389.2114\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2182.0271\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2213.4180\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2336.4639\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2309.5269\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2147.8938\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2209.9739\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1953.8263\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2426.2427\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2306.3479\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2397.3101\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 73.8153\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18918.4258\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 9547.2861\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5216.8389\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3229.4788\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2444.7156\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2348.5264\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1658.7007\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1949.7236\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1829.7954\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1595.7852\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1767.2500\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1845.6451\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1591.6948\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1549.0212\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1640.3494\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1769.2089\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1535.7407\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1568.9055\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1893.5688\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1792.3319\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 63.7136\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9287.4639\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6807.2817\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6352.9116\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6141.7188\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6552.5508\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 522.8948\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9205.6787\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5806.9663\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4980.8574\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4442.2056\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4238.6318\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 348.3826\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 19911.3770\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6829.4458\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5195.9536\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5735.2935\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5473.2891\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 41.5347\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 32807.0117\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 32806.1797\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 32802.8828\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 32816.0312\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 32811.5703\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 32802.9219\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 32810.5273\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 32799.5703\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 32802.4688\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 32800.5938\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166CBE523A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166CBE523A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 32857.2500\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 33313.9023\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 33305.1055\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 33332.7188\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 33325.6523\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 33329.9492\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 33307.4453\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 33302.5898\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 33297.5938\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 33309.8984\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 33306.3867\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D05A8B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D05A8B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 33507.3359\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 33119.6250\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 33113.7344\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 33121.1875\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 33110.0664\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 33105.4570\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 33104.5625\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 33118.9805\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 33106.7070\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 33102.2188\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 33102.8906\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166CBD349D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166CBD349D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 32840.8125\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 28761.2715\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8939.5674\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2374.2581\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 855.8380\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 530.2497\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 458.7123\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 446.2542\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 441.2148\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 439.9209\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 439.7224\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 440.3594\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 439.8378\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 440.1185\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 439.7737\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 439.6212\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D05A8AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D05A8AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 491.4814\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 27455.4180\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9797.8428\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3284.0098\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1332.9003\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 730.5225\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 552.1594\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 498.1995\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 482.3916\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 476.9313\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 474.8226\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 475.1827\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 474.9087\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 475.9870\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 474.7736\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 475.0673\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166CBAD8318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166CBAD8318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 421.2881\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 29064.9883\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 10200.7949\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2663.6653\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 956.2637\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 572.8765\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 482.6631\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 462.6727\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 456.5299\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 456.6284\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 456.3909\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 457.4659\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 456.9365\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 456.3381\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 457.9577\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 457.1222\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D1911CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D1911CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 458.3717\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 32449.1250\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32241.5391\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 32083.8730\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 32014.9941\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31939.7910\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31836.8730\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31795.1094\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31779.3262\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31688.0566\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31589.3730\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31556.2246\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31519.3652\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31463.3262\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31417.8125\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31368.5137\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31320.0781\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31267.2559\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31204.5195\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31185.8789\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31176.4141\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D181D9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000166D181D9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 31178.2695\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32672.1953\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32529.6289\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 32426.7734\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32369.5020\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32311.5352\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 32255.6504\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32211.0059\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32117.5703\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32093.8887\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32050.2559\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 32008.4082\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31973.7910\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31914.4980\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31858.1152\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31828.6133\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31769.8730\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31706.4199\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31695.6445\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31623.3398\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 31578.7949\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31747.6777\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 32790.6445\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32674.6016\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32585.3828\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32529.6484\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32481.1211\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32413.2695\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 32354.1465\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32274.9160\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32281.7148\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 32132.607 - 0s 3ms/step - loss: 32198.0645\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32142.3223\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32115.2324\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32044.1152\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31988.3379\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31953.1152\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31909.9570\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31894.5430\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31806.4062\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31794.3516\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 31674.3574\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 31451.4277\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32878.4492\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32709.2812\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32607.2656\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32521.4766\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 32446.0840\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32478.5000\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-277b53bfb268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnome\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mscd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_default\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-5ac14c779a9f>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m#Treinando modelos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_tuned\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-5ac14c779a9f>\u001b[0m in \u001b[0;36mfit_tuned\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mtime_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m#Tempo de treinamento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m                     \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    970\u001b[0m                 ))\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Whitelisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    798\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1211\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m   \u001b[1;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2945\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;31m# such as loss scaling and gradient clipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n\u001b[1;32m--> 757\u001b[1;33m               self.trainable_variables)\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_minimize\u001b[1;34m(strategy, tape, optimizer, loss, trainable_variables)\u001b[0m\n\u001b[0;32m   2720\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scaled_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2722\u001b[1;33m   \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m   \u001b[1;31m# Whether to aggregate gradients outside of optimizer. This requires support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n\u001b[1;32m-> 1325\u001b[1;33m       SmartBroadcastGradientArgs(x, y, grad))\n\u001b[0m\u001b[0;32m   1326\u001b[0m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[1;34m(x, y, grad)\u001b[0m\n\u001b[0;32m    106\u001b[0m       y_shape_tuple is None or None in y_shape_tuple):\n\u001b[0;32m    107\u001b[0m     \u001b[0msx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0msy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0mrx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   9034\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"out_type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9035\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m-> 9036\u001b[1;33m         \"Shape\", input=input, out_type=out_type, name=name)\n\u001b[0m\u001b[0;32m   9037\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9038\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    591\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3483\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3485\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3487\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 1975\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1785\u001b[0m   op_desc = pywrap_tf_session.TF_NewOperation(graph._c_graph,\n\u001b[0;32m   1786\u001b[0m                                               \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m                                               compat.as_str(node_def.name))\n\u001b[0m\u001b[0;32m   1788\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m     \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_SetDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [randomNN, bayesNN]\n",
    "\n",
    "opt = ['Random', 'Bayesian']\n",
    "names = []\n",
    "sc =[]\n",
    "scd=[]\n",
    "sct=[]\n",
    "tm = []\n",
    "tmt=[]\n",
    "\n",
    "for i,m in enumerate(models):\n",
    "    nome = str(opt[i])\n",
    "    names.append(nome)\n",
    "    m.search(X_train, X_test, y_train, y_test)\n",
    "    sc.append(m.score)\n",
    "    scd.append(m.score_default)\n",
    "    sct.append(m.score_tuned)\n",
    "    tm.append(m.time)\n",
    "    tmt.append(m.time_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "FlfdkI-08IP0",
    "outputId": "cf1fd623-4d9a-43f3-8dbb-0ff59f93f404"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(np.arange(len(sc)),sct, width=0.6)\n",
    "plt.hlines(0.9, 0, len(sc), colors='red')\n",
    "plt.xticks(np.arange(len(names)), names, rotation=280)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBxQHkQjAbVL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classe_Otimizacao2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
